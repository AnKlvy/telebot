"""
Middleware –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±–æ—Ç–∞
"""
import time
import asyncio
import logging
import json
from typing import Callable, Dict, Any, Awaitable
from aiogram import BaseMiddleware
from aiogram.types import Message, CallbackQuery, Update
from utils.redis_manager import RedisManager
from utils.config import REDIS_ENABLED
from datetime import datetime, timedelta
import psutil
import os

logger = logging.getLogger(__name__)

class PerformanceMiddleware(BaseMiddleware):
    """Middleware –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self):
        self.redis_manager = RedisManager() if REDIS_ENABLED else None
        self.request_times = []
        self.active_requests = 0
        self.max_concurrent_requests = 0
        
    async def __call__(
        self,
        handler: Callable[[Message | CallbackQuery, Dict[str, Any]], Awaitable[Any]],
        event: Message | CallbackQuery,
        data: Dict[str, Any]
    ) -> Any:
        start_time = time.time()
        self.active_requests += 1
        self.max_concurrent_requests = max(self.max_concurrent_requests, self.active_requests)
        
        user_id = event.from_user.id
        event_type = "message" if isinstance(event, Message) else "callback"
        
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
            result = await handler(event, data)
            
            # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            execution_time = time.time() - start_time
            self.request_times.append(execution_time)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (>1 —Å–µ–∫—É–Ω–¥—ã)
            if execution_time > 1.0:
                logger.warning(f"üêå –ú–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {execution_time:.2f}—Å | User: {user_id} | Type: {event_type}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ Redis
            await self._save_metrics(user_id, event_type, execution_time)
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∑–∞–ø—Ä–æ—Å–µ: {e} | Time: {execution_time:.2f}—Å | User: {user_id}")
            raise
        finally:
            self.active_requests -= 1
    
    async def _save_metrics(self, user_id: int, event_type: str, execution_time: float):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ Redis"""
        if not self.redis_manager or not await self.redis_manager.is_connected():
            return
        
        try:
            timestamp = datetime.now().isoformat()
            metric_data = {
                'user_id': user_id,
                'event_type': event_type,
                'execution_time': execution_time,
                'timestamp': timestamp,
                'active_requests': self.active_requests,
                'memory_usage': psutil.Process().memory_info().rss / 1024 / 1024  # MB
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Redis —Å TTL 1 —á–∞—Å
            key = f"performance_metrics:{timestamp}"
            await self.redis_manager.set(key, json.dumps(metric_data), 3600)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            await self._update_aggregate_stats(execution_time)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")
    
    async def _update_aggregate_stats(self, execution_time: float):
        """–û–±–Ω–æ–≤–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        if not self.redis_manager or not await self.redis_manager.is_connected():
            return
        
        try:
            stats_key = "performance_stats"
            stats_data = await self.redis_manager.get(stats_key)
            
            if stats_data:
                stats = json.loads(stats_data)
            else:
                stats = {
                    'total_requests': 0,
                    'total_time': 0,
                    'min_time': float('inf'),
                    'max_time': 0,
                    'max_concurrent': 0
                }
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats['total_requests'] += 1
            stats['total_time'] += execution_time
            stats['min_time'] = min(stats['min_time'], execution_time)
            stats['max_time'] = max(stats['max_time'], execution_time)
            stats['max_concurrent'] = max(stats['max_concurrent'], self.max_concurrent_requests)
            stats['avg_time'] = stats['total_time'] / stats['total_requests']
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            await self.redis_manager.set(stats_key, json.dumps(stats), 86400)  # 24 —á–∞—Å–∞
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    def get_current_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if not self.request_times:
            return {}
        
        recent_times = self.request_times[-100:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø—Ä–æ—Å–æ–≤
        
        return {
            'active_requests': self.active_requests,
            'max_concurrent_requests': self.max_concurrent_requests,
            'avg_response_time': sum(recent_times) / len(recent_times),
            'min_response_time': min(recent_times),
            'max_response_time': max(recent_times),
            'total_requests': len(self.request_times),
            'memory_usage_mb': psutil.Process().memory_info().rss / 1024 / 1024,
            'cpu_percent': psutil.Process().cpu_percent()
        }


class DatabasePerformanceMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        self.query_times = []
        self.redis_manager = RedisManager() if REDIS_ENABLED else None
    
    async def log_query(self, query: str, execution_time: float):
        """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ –ë–î"""
        self.query_times.append(execution_time)
        
        if execution_time > 0.5:  # –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã >500ms
            logger.warning(f"üêå –ú–µ–¥–ª–µ–Ω–Ω—ã–π SQL –∑–∞–ø—Ä–æ—Å: {execution_time:.3f}—Å | {query[:100]}...")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Redis
        if self.redis_manager and await self.redis_manager.is_connected():
            try:
                metric_data = {
                    'query': query[:200],  # –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤
                    'execution_time': execution_time,
                    'timestamp': datetime.now().isoformat()
                }
                key = f"db_metrics:{datetime.now().isoformat()}"
                await self.redis_manager.set(key, json.dumps(metric_data), 3600)
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –ë–î: {e}")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–Ω–∏—Ç–æ—Ä–∞ –ë–î
db_monitor = DatabasePerformanceMonitor()
