#!/usr/bin/env python3
"""
–ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å PostgreSQL –ø–æ–¥ –Ω–∞–≥—Ä—É–∑–∫–æ–π
"""
import asyncio
import asyncpg
import time
import json
import argparse
import random
import statistics
from datetime import datetime
from typing import List, Dict, Any
from dataclasses import dataclass
import os
from dotenv import load_dotenv

load_dotenv()

@dataclass
class DatabaseOperation:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
    operation_type: str
    execution_time: float
    success: bool
    rows_affected: int = 0
    error: str = None

class DatabaseStressTester:
    """–¢–µ—Å—Ç–µ—Ä –Ω–∞–≥—Ä—É–∑–∫–∏ –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
        self.db_config = {
            "host": os.getenv("POSTGRES_HOST", "localhost"),
            "port": int(os.getenv("POSTGRES_PORT", "5432")),
            "database": os.getenv("POSTGRES_DB", "telebot"),
            "user": os.getenv("POSTGRES_USER", "telebot_user"),
            "password": os.getenv("POSTGRES_PASSWORD", "your_secure_password")
        }
        self.operations: List[DatabaseOperation] = []
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.test_courses = ["Python", "JavaScript", "SQL", "DevOps", "ML"]
        self.test_subjects = ["–û—Å–Ω–æ–≤—ã", "–ü—Ä–∞–∫—Ç–∏–∫–∞", "–ü—Ä–æ–µ–∫—Ç—ã", "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"]
        self.test_names = ["–ò–≤–∞–Ω", "–ú–∞—Ä–∏—è", "–ê–ª–µ–∫—Å–µ–π", "–ï–ª–µ–Ω–∞", "–î–º–∏—Ç—Ä–∏–π", "–ê–Ω–Ω–∞"]
        self.test_surnames = ["–ò–≤–∞–Ω–æ–≤", "–ü–µ—Ç—Ä–æ–≤", "–°–∏–¥–æ—Ä–æ–≤", "–ö–æ–∑–ª–æ–≤", "–ù–æ–≤–∏–∫–æ–≤"]
    
    async def create_connection_pool(self, pool_size: int = 20) -> asyncpg.Pool:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        try:
            pool = await asyncpg.create_pool(
                **self.db_config,
                min_size=5,
                max_size=pool_size,
                command_timeout=30
            )
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π (—Ä–∞–∑–º–µ—Ä: {pool_size})")
            return pool
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {e}")
            raise
    
    async def test_select_operations(self, pool: asyncpg.Pool, operations_count: int):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SELECT –æ–ø–µ—Ä–∞—Ü–∏–π"""
        queries = [
            "SELECT COUNT(*) FROM users",
            "SELECT * FROM courses LIMIT 10",
            "SELECT * FROM subjects WHERE course_id = $1",
            "SELECT u.name, c.name FROM users u JOIN students s ON u.telegram_id = s.telegram_id JOIN courses c ON s.course_id = c.id LIMIT 5",
            "SELECT COUNT(*) FROM microtopics WHERE subject_id = $1"
        ]
        
        for i in range(operations_count):
            query = random.choice(queries)
            start_time = time.time()
            
            try:
                async with pool.acquire() as conn:
                    if "$1" in query:
                        # –ó–∞–ø—Ä–æ—Å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º
                        param = random.randint(1, 10)
                        result = await conn.fetch(query, param)
                    else:
                        result = await conn.fetch(query)
                    
                    execution_time = time.time() - start_time
                    
                    self.operations.append(DatabaseOperation(
                        operation_type="SELECT",
                        execution_time=execution_time,
                        success=True,
                        rows_affected=len(result)
                    ))
                    
            except Exception as e:
                execution_time = time.time() - start_time
                self.operations.append(DatabaseOperation(
                    operation_type="SELECT",
                    execution_time=execution_time,
                    success=False,
                    error=str(e)
                ))
    
    async def test_insert_operations(self, pool: asyncpg.Pool, operations_count: int):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ INSERT –æ–ø–µ—Ä–∞—Ü–∏–π"""
        for i in range(operations_count):
            start_time = time.time()
            
            try:
                async with pool.acquire() as conn:
                    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    telegram_id = 9000000 + i
                    name = f"{random.choice(self.test_names)} {random.choice(self.test_surnames)}"
                    
                    await conn.execute(
                        "INSERT INTO users (telegram_id, name) VALUES ($1, $2) ON CONFLICT (telegram_id) DO NOTHING",
                        telegram_id, name
                    )
                    
                    execution_time = time.time() - start_time
                    
                    self.operations.append(DatabaseOperation(
                        operation_type="INSERT",
                        execution_time=execution_time,
                        success=True,
                        rows_affected=1
                    ))
                    
            except Exception as e:
                execution_time = time.time() - start_time
                self.operations.append(DatabaseOperation(
                    operation_type="INSERT",
                    execution_time=execution_time,
                    success=False,
                    error=str(e)
                ))
    
    async def test_update_operations(self, pool: asyncpg.Pool, operations_count: int):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ UPDATE –æ–ø–µ—Ä–∞—Ü–∏–π"""
        for i in range(operations_count):
            start_time = time.time()
            
            try:
                async with pool.acquire() as conn:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    telegram_id = 9000000 + random.randint(0, 100)
                    new_name = f"{random.choice(self.test_names)} {random.choice(self.test_surnames)} (Updated)"
                    
                    result = await conn.execute(
                        "UPDATE users SET name = $1 WHERE telegram_id = $2",
                        new_name, telegram_id
                    )
                    
                    execution_time = time.time() - start_time
                    
                    self.operations.append(DatabaseOperation(
                        operation_type="UPDATE",
                        execution_time=execution_time,
                        success=True,
                        rows_affected=1
                    ))
                    
            except Exception as e:
                execution_time = time.time() - start_time
                self.operations.append(DatabaseOperation(
                    operation_type="UPDATE",
                    execution_time=execution_time,
                    success=False,
                    error=str(e)
                ))
    
    async def test_complex_queries(self, pool: asyncpg.Pool, operations_count: int):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        complex_queries = [
            """
            SELECT 
                c.name as course_name,
                COUNT(s.telegram_id) as students_count,
                AVG(CASE WHEN s.telegram_id IS NOT NULL THEN 1 ELSE 0 END) as avg_activity
            FROM courses c
            LEFT JOIN students s ON c.id = s.course_id
            GROUP BY c.id, c.name
            """,
            """
            SELECT 
                sub.name as subject_name,
                COUNT(m.id) as microtopics_count
            FROM subjects sub
            LEFT JOIN microtopics m ON sub.id = m.subject_id
            GROUP BY sub.id, sub.name
            ORDER BY microtopics_count DESC
            """,
            """
            SELECT 
                u.name,
                COUNT(DISTINCT s.course_id) as courses_count
            FROM users u
            JOIN students s ON u.telegram_id = s.telegram_id
            GROUP BY u.telegram_id, u.name
            HAVING COUNT(DISTINCT s.course_id) > 0
            """
        ]
        
        for i in range(operations_count):
            query = random.choice(complex_queries)
            start_time = time.time()
            
            try:
                async with pool.acquire() as conn:
                    result = await conn.fetch(query)
                    execution_time = time.time() - start_time
                    
                    self.operations.append(DatabaseOperation(
                        operation_type="COMPLEX_SELECT",
                        execution_time=execution_time,
                        success=True,
                        rows_affected=len(result)
                    ))
                    
            except Exception as e:
                execution_time = time.time() - start_time
                self.operations.append(DatabaseOperation(
                    operation_type="COMPLEX_SELECT",
                    execution_time=execution_time,
                    success=False,
                    error=str(e)
                ))
    
    async def worker(self, pool: asyncpg.Pool, worker_id: int, operations_per_worker: int):
        """–†–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π"""
        print(f"üîß –í–æ—Ä–∫–µ—Ä {worker_id} –Ω–∞—á–∞–ª —Ä–∞–±–æ—Ç—É")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏
        select_ops = operations_per_worker // 2
        insert_ops = operations_per_worker // 4
        update_ops = operations_per_worker // 8
        complex_ops = operations_per_worker - select_ops - insert_ops - update_ops
        
        tasks = [
            self.test_select_operations(pool, select_ops),
            self.test_insert_operations(pool, insert_ops),
            self.test_update_operations(pool, update_ops),
            self.test_complex_queries(pool, complex_ops)
        ]
        
        await asyncio.gather(*tasks)
        print(f"‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id} –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É")
    
    async def run_stress_test(self, concurrent_workers: int = 10, operations_per_worker: int = 100):
        """–ó–∞–ø—É—Å–∫ –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞"""
        print(f"üöÄ –ó–∞–ø—É—Å–∫ –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        print(f"üîß –í–æ—Ä–∫–µ—Ä–æ–≤: {concurrent_workers}")
        print(f"üìä –û–ø–µ—Ä–∞—Ü–∏–π –Ω–∞ –≤–æ—Ä–∫–µ—Ä–∞: {operations_per_worker}")
        print(f"üìà –í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π: {concurrent_workers * operations_per_worker}")
        
        # –°–æ–∑–¥–∞–µ–º –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        pool = await self.create_connection_pool(concurrent_workers + 5)
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–æ—Ä–∫–µ—Ä–æ–≤
            tasks = []
            for worker_id in range(concurrent_workers):
                task = asyncio.create_task(
                    self.worker(pool, worker_id, operations_per_worker)
                )
                tasks.append(task)
            
            start_time = time.time()
            await asyncio.gather(*tasks)
            total_time = time.time() - start_time
            
            self.generate_report(total_time)
            
        finally:
            await pool.close()
    
    def generate_report(self, total_time: float):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏"""
        if not self.operations:
            print("‚ùå –ù–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        successful_ops = [op for op in self.operations if op.success]
        failed_ops = [op for op in self.operations if not op.success]
        
        print("\n" + "="*60)
        print("üìä –û–¢–ß–ï–¢ –û –ù–ê–ì–†–£–ó–û–ß–ù–û–ú –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ò –ë–î")
        print("="*60)
        
        print(f"üìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π: {len(self.operations)}")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö: {len(successful_ops)} ({len(successful_ops)/len(self.operations)*100:.1f}%)")
        print(f"   –ù–µ—É–¥–∞—á–Ω—ã—Ö: {len(failed_ops)} ({len(failed_ops)/len(self.operations)*100:.1f}%)")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫")
        print(f"   –û–ø–µ—Ä–∞—Ü–∏–π –≤ —Å–µ–∫—É–Ω–¥—É: {len(self.operations)/total_time:.2f}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –æ–ø–µ—Ä–∞—Ü–∏–π
        op_types = {}
        for op in successful_ops:
            if op.operation_type not in op_types:
                op_types[op.operation_type] = []
            op_types[op.operation_type].append(op.execution_time)
        
        print(f"\n‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ —Ç–∏–ø–∞–º –æ–ø–µ—Ä–∞—Ü–∏–π:")
        for op_type, times in op_types.items():
            avg_time = statistics.mean(times)
            min_time = min(times)
            max_time = max(times)
            print(f"   {op_type}:")
            print(f"     –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(times)}")
            print(f"     –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time:.4f} —Å–µ–∫")
            print(f"     –ú–∏–Ω/–ú–∞–∫—Å: {min_time:.4f} / {max_time:.4f} —Å–µ–∫")
        
        if failed_ops:
            print(f"\n‚ùå –û—à–∏–±–∫–∏:")
            error_counts = {}
            for op in failed_ops:
                error = op.error or "Unknown error"
                error_counts[error] = error_counts.get(error, 0) + 1
            
            for error, count in error_counts.items():
                print(f"   {error}: {count}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        self.save_detailed_report()
    
    def save_detailed_report(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–∞–π–ª"""
        os.makedirs("load_testing/reports", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"load_testing/reports/database_test_{timestamp}.json"
        
        report_data = {
            "test_config": {
                "database_host": self.db_config["host"],
                "database_name": self.db_config["database"],
                "timestamp": timestamp
            },
            "operations": [
                {
                    "operation_type": op.operation_type,
                    "execution_time": op.execution_time,
                    "success": op.success,
                    "rows_affected": op.rows_affected,
                    "error": op.error
                }
                for op in self.operations
            ]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")

async def main():
    parser = argparse.ArgumentParser(description='–ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--workers', type=int, default=10, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤')
    parser.add_argument('--operations', type=int, default=100, help='–û–ø–µ—Ä–∞—Ü–∏–π –Ω–∞ –≤–æ—Ä–∫–µ—Ä–∞')
    
    args = parser.parse_args()
    
    tester = DatabaseStressTester()
    await tester.run_stress_test(args.workers, args.operations)

if __name__ == "__main__":
    asyncio.run(main())
