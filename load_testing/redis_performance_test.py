#!/usr/bin/env python3
"""
–ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Redis
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–¥ –Ω–∞–≥—Ä—É–∑–∫–æ–π
"""
import asyncio
import aioredis
import time
import json
import argparse
import random
import statistics
import string
from datetime import datetime
from typing import List, Dict, Any
from dataclasses import dataclass
import os
from dotenv import load_dotenv

load_dotenv()

@dataclass
class RedisOperation:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å Redis"""
    operation_type: str
    execution_time: float
    success: bool
    key: str = None
    error: str = None

class RedisPerformanceTester:
    """–¢–µ—Å—Ç–µ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ Redis"""
    
    def __init__(self):
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Redis
        self.redis_host = os.getenv("REDIS_HOST", "localhost")
        self.redis_port = int(os.getenv("REDIS_PORT", "6379"))
        self.redis_db = int(os.getenv("REDIS_DB", "0"))
        self.redis_password = os.getenv("REDIS_PASSWORD", None)
        
        self.operations: List[RedisOperation] = []
        self.redis_pool = None
    
    async def create_redis_pool(self, pool_size: int = 20) -> aioredis.ConnectionPool:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π Redis"""
        try:
            self.redis_pool = aioredis.ConnectionPool.from_url(
                f"redis://{self.redis_host}:{self.redis_port}/{self.redis_db}",
                password=self.redis_password,
                max_connections=pool_size,
                encoding="utf-8",
                decode_responses=True
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            redis = aioredis.Redis(connection_pool=self.redis_pool)
            await redis.ping()
            await redis.close()
            
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π Redis (—Ä–∞–∑–º–µ—Ä: {pool_size})")
            return self.redis_pool
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—É–ª–∞ Redis: {e}")
            raise
    
    def generate_test_data(self, size: str = "small") -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Ä–∞–∑–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞"""
        sizes = {
            "small": 100,      # 100 –±–∞–π—Ç
            "medium": 1024,    # 1 KB
            "large": 10240,    # 10 KB
            "xlarge": 102400   # 100 KB
        }
        
        data_size = sizes.get(size, 100)
        return ''.join(random.choices(string.ascii_letters + string.digits, k=data_size))
    
    async def test_set_operations(self, operations_count: int, data_size: str = "small"):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SET –æ–ø–µ—Ä–∞—Ü–∏–π"""
        redis = aioredis.Redis(connection_pool=self.redis_pool)
        
        try:
            for i in range(operations_count):
                key = f"test:set:{i}:{random.randint(1000, 9999)}"
                value = self.generate_test_data(data_size)
                start_time = time.time()
                
                try:
                    await redis.set(key, value, ex=3600)  # TTL 1 —á–∞—Å
                    execution_time = time.time() - start_time
                    
                    self.operations.append(RedisOperation(
                        operation_type="SET",
                        execution_time=execution_time,
                        success=True,
                        key=key
                    ))
                    
                except Exception as e:
                    execution_time = time.time() - start_time
                    self.operations.append(RedisOperation(
                        operation_type="SET",
                        execution_time=execution_time,
                        success=False,
                        key=key,
                        error=str(e)
                    ))
        finally:
            await redis.close()
    
    async def test_get_operations(self, operations_count: int):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GET –æ–ø–µ—Ä–∞—Ü–∏–π"""
        redis = aioredis.Redis(connection_pool=self.redis_pool)
        
        try:
            # –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–µ–º –∫–ª—é—á–∏ –¥–ª—è —á—Ç–µ–Ω–∏—è
            test_keys = []
            for i in range(min(100, operations_count)):
                key = f"test:get:{i}"
                value = self.generate_test_data("medium")
                await redis.set(key, value, ex=3600)
                test_keys.append(key)
            
            # –¢–µ–ø–µ—Ä—å —á–∏—Ç–∞–µ–º
            for i in range(operations_count):
                key = random.choice(test_keys)
                start_time = time.time()
                
                try:
                    result = await redis.get(key)
                    execution_time = time.time() - start_time
                    
                    self.operations.append(RedisOperation(
                        operation_type="GET",
                        execution_time=execution_time,
                        success=result is not None,
                        key=key
                    ))
                    
                except Exception as e:
                    execution_time = time.time() - start_time
                    self.operations.append(RedisOperation(
                        operation_type="GET",
                        execution_time=execution_time,
                        success=False,
                        key=key,
                        error=str(e)
                    ))
        finally:
            await redis.close()
    
    async def test_hash_operations(self, operations_count: int):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–π —Å —Ö—ç—à–∞–º–∏"""
        redis = aioredis.Redis(connection_pool=self.redis_pool)
        
        try:
            for i in range(operations_count):
                hash_key = f"test:hash:{i // 10}"  # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ 10
                field = f"field_{i % 10}"
                value = self.generate_test_data("small")
                start_time = time.time()
                
                try:
                    await redis.hset(hash_key, field, value)
                    execution_time = time.time() - start_time
                    
                    self.operations.append(RedisOperation(
                        operation_type="HSET",
                        execution_time=execution_time,
                        success=True,
                        key=f"{hash_key}:{field}"
                    ))
                    
                except Exception as e:
                    execution_time = time.time() - start_time
                    self.operations.append(RedisOperation(
                        operation_type="HSET",
                        execution_time=execution_time,
                        success=False,
                        key=f"{hash_key}:{field}",
                        error=str(e)
                    ))
        finally:
            await redis.close()
    
    async def test_list_operations(self, operations_count: int):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–π —Å–æ —Å–ø–∏—Å–∫–∞–º–∏"""
        redis = aioredis.Redis(connection_pool=self.redis_pool)
        
        try:
            list_key = "test:list:performance"
            
            for i in range(operations_count):
                value = f"list_item_{i}_{random.randint(1000, 9999)}"
                start_time = time.time()
                
                try:
                    if i % 2 == 0:
                        # LPUSH
                        await redis.lpush(list_key, value)
                        op_type = "LPUSH"
                    else:
                        # RPOP
                        result = await redis.rpop(list_key)
                        op_type = "RPOP"
                    
                    execution_time = time.time() - start_time
                    
                    self.operations.append(RedisOperation(
                        operation_type=op_type,
                        execution_time=execution_time,
                        success=True,
                        key=list_key
                    ))
                    
                except Exception as e:
                    execution_time = time.time() - start_time
                    self.operations.append(RedisOperation(
                        operation_type=op_type,
                        execution_time=execution_time,
                        success=False,
                        key=list_key,
                        error=str(e)
                    ))
        finally:
            await redis.close()
    
    async def test_pipeline_operations(self, operations_count: int):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π (pipeline)"""
        redis = aioredis.Redis(connection_pool=self.redis_pool)
        
        try:
            batch_size = 10
            for batch_start in range(0, operations_count, batch_size):
                start_time = time.time()
                
                try:
                    pipe = redis.pipeline()
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ –ø–∞–∫–µ—Ç
                    for i in range(batch_start, min(batch_start + batch_size, operations_count)):
                        key = f"test:pipeline:{i}"
                        value = self.generate_test_data("small")
                        pipe.set(key, value, ex=3600)
                    
                    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞–∫–µ—Ç
                    await pipe.execute()
                    execution_time = time.time() - start_time
                    
                    self.operations.append(RedisOperation(
                        operation_type="PIPELINE",
                        execution_time=execution_time,
                        success=True,
                        key=f"batch_{batch_start}_{batch_start + batch_size}"
                    ))
                    
                except Exception as e:
                    execution_time = time.time() - start_time
                    self.operations.append(RedisOperation(
                        operation_type="PIPELINE",
                        execution_time=execution_time,
                        success=False,
                        key=f"batch_{batch_start}_{batch_start + batch_size}",
                        error=str(e)
                    ))
        finally:
            await redis.close()
    
    async def worker(self, worker_id: int, operations_per_worker: int):
        """–†–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π"""
        print(f"üîß Redis –≤–æ—Ä–∫–µ—Ä {worker_id} –Ω–∞—á–∞–ª —Ä–∞–±–æ—Ç—É")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏
        set_ops = operations_per_worker // 3
        get_ops = operations_per_worker // 3
        hash_ops = operations_per_worker // 6
        list_ops = operations_per_worker // 6
        pipeline_ops = operations_per_worker - set_ops - get_ops - hash_ops - list_ops
        
        tasks = [
            self.test_set_operations(set_ops, "medium"),
            self.test_get_operations(get_ops),
            self.test_hash_operations(hash_ops),
            self.test_list_operations(list_ops),
            self.test_pipeline_operations(pipeline_ops)
        ]
        
        await asyncio.gather(*tasks)
        print(f"‚úÖ Redis –≤–æ—Ä–∫–µ—Ä {worker_id} –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É")
    
    async def run_performance_test(self, concurrent_workers: int = 10, operations_per_worker: int = 100):
        """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        print(f"üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ Redis")
        print(f"üîß –í–æ—Ä–∫–µ—Ä–æ–≤: {concurrent_workers}")
        print(f"üìä –û–ø–µ—Ä–∞—Ü–∏–π –Ω–∞ –≤–æ—Ä–∫–µ—Ä–∞: {operations_per_worker}")
        print(f"üìà –í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π: {concurrent_workers * operations_per_worker}")
        
        # –°–æ–∑–¥–∞–µ–º –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        await self.create_redis_pool(concurrent_workers + 5)
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–æ—Ä–∫–µ—Ä–æ–≤
            tasks = []
            for worker_id in range(concurrent_workers):
                task = asyncio.create_task(
                    self.worker(worker_id, operations_per_worker)
                )
                tasks.append(task)
            
            start_time = time.time()
            await asyncio.gather(*tasks)
            total_time = time.time() - start_time
            
            self.generate_report(total_time)
            
        finally:
            if self.redis_pool:
                await self.redis_pool.disconnect()
    
    def generate_report(self, total_time: float):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏"""
        if not self.operations:
            print("‚ùå –ù–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        successful_ops = [op for op in self.operations if op.success]
        failed_ops = [op for op in self.operations if not op.success]
        
        print("\n" + "="*60)
        print("üìä –û–¢–ß–ï–¢ –û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ò –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò REDIS")
        print("="*60)
        
        print(f"üìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π: {len(self.operations)}")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö: {len(successful_ops)} ({len(successful_ops)/len(self.operations)*100:.1f}%)")
        print(f"   –ù–µ—É–¥–∞—á–Ω—ã—Ö: {len(failed_ops)} ({len(failed_ops)/len(self.operations)*100:.1f}%)")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫")
        print(f"   –û–ø–µ—Ä–∞—Ü–∏–π –≤ —Å–µ–∫—É–Ω–¥—É: {len(self.operations)/total_time:.2f}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –æ–ø–µ—Ä–∞—Ü–∏–π
        op_types = {}
        for op in successful_ops:
            if op.operation_type not in op_types:
                op_types[op.operation_type] = []
            op_types[op.operation_type].append(op.execution_time)
        
        print(f"\n‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ —Ç–∏–ø–∞–º –æ–ø–µ—Ä–∞—Ü–∏–π:")
        for op_type, times in op_types.items():
            if times:
                avg_time = statistics.mean(times)
                min_time = min(times)
                max_time = max(times)
                print(f"   {op_type}:")
                print(f"     –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(times)}")
                print(f"     –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time:.4f} —Å–µ–∫")
                print(f"     –ú–∏–Ω/–ú–∞–∫—Å: {min_time:.4f} / {max_time:.4f} —Å–µ–∫")
        
        if failed_ops:
            print(f"\n‚ùå –û—à–∏–±–∫–∏:")
            error_counts = {}
            for op in failed_ops:
                error = op.error or "Unknown error"
                error_counts[error] = error_counts.get(error, 0) + 1
            
            for error, count in error_counts.items():
                print(f"   {error}: {count}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        self.save_detailed_report()
    
    def save_detailed_report(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–∞–π–ª"""
        os.makedirs("load_testing/reports", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"load_testing/reports/redis_test_{timestamp}.json"
        
        report_data = {
            "test_config": {
                "redis_host": self.redis_host,
                "redis_port": self.redis_port,
                "redis_db": self.redis_db,
                "timestamp": timestamp
            },
            "operations": [
                {
                    "operation_type": op.operation_type,
                    "execution_time": op.execution_time,
                    "success": op.success,
                    "key": op.key,
                    "error": op.error
                }
                for op in self.operations
            ]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")

async def main():
    parser = argparse.ArgumentParser(description='–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ Redis')
    parser.add_argument('--workers', type=int, default=10, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤')
    parser.add_argument('--operations', type=int, default=100, help='–û–ø–µ—Ä–∞—Ü–∏–π –Ω–∞ –≤–æ—Ä–∫–µ—Ä–∞')
    
    args = parser.parse_args()
    
    tester = RedisPerformanceTester()
    await tester.run_performance_test(args.workers, args.operations)

if __name__ == "__main__":
    asyncio.run(main())
